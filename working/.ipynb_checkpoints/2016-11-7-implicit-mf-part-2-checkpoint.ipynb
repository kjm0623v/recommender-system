{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{align}\n",
    "\\normalsize {\\text{BPR-O}} \\small {\\text{PT}} :&= ln\\ p(\\Theta \\lvert >_u) \\\\\n",
    "&= ln p(>_u \\lvert \\Theta)p(\\Theta)\n",
    "&= ln \\prod_{(u,i,j) \\in D_S} \\sigma(\\hat x_{uij})p(\\Theta) \\\\\n",
    "&= \\displaystyle \\sum_{(u,i,j) \\in D_S} ln\\ \\sigma(\\hat x_{uij}) + ln\\ p(\\Theta) \\\\\n",
    "&= \\displaystyle \\sum_{(u,i,j) \\in D_S} ln\\ \\sigma(\\hat x_{uij}) - \\lambda_{\\Theta} \\lVert \\Theta \\rVert^2 \\\\$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{align}\n",
    "\\prod_{u \\in U} p(>_u \\lvert \\Theta) = &\\prod_{(u,i,j) \\in U \\times I \\times I} p(i >_u j \\lvert \\Theta)^{\\delta((u,i,j) \\in D_S)} \\\\ &\\cdot (1 - p(i >_u j \\lvert \\Theta))^{\\delta((u,j,i) \\notin D_S)} \\\\\n",
    "\\end{align}$$ \n",
    "$$\\prod_{u \\in U} p(>_u \\lvert \\Theta) = \\prod_{(u,i,j) \\in D_S} p(i>_u j \\lvert \\Theta)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\tiny{A} \\scriptsize{A}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 내용은 Ethan Rosenthal의 블로그의 내용과 소스코드를 바탕으로 번역 및 일부 수정한 내용입니다.\n",
    "\n",
    "원본을 보시고 싶으신 분은 아래 사이트를 방문해주세요\n",
    "\n",
    "- 블로그: http://blog.ethanrosenthal.com/\n",
    "- github: https://github.com/EthanRosenthal/DataPiques_source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번 post에서는 새로운 두 가지 패키지를 사용해서 implicit matrix factorization의 WARP를 구현할 예정이다. WARP는 학습할 때 두 item 의 rank에 대해서 고려하기 때문에 ***Learning to Rank*** 라고 한다.\n",
    "\n",
    "### 패키지\n",
    "\n",
    "1. [LightFM](http://lyst.github.io/lightfm/docs/home.html): BPR, WARP 등 여러가지 implicit MF 모델이 구현되어 있다. 이 중 WARP를 택해서 학습시키고 결과를 확인한다. Cython으로 작성되었고 HOGWILD SGD로 병렬처리가 되어 있어서 학습이 매우 빠르다. \n",
    "    - 설치 방법: pip install lightfm <br><br>\n",
    "2. [scikit-optimize](https://scikit-optimize.github.io/): optimization에 사용되는 패키지로 좀 더 빠르게 모델에 적합한 hyperparameter를 찾기 위해 사용한다.\n",
    "    - 설치 방법: pip install scikit-optimize\n",
    "    \n",
    "### 모델 소개\n",
    "\n",
    "앞에서 다룬 내용에서는 데이터셋 하나씩만을 가지고(*explicit feedback, implicit feedback*) 하나의 모델을 학습시키는 형식으로 진행되었다.\n",
    "이번에는 implicit feedback과 item에 관련된 feature, 두 가지 데이터를 사용해서 모델을 학습시켜보고 그렇지 않을 때와 성능을 비교해보도록 하자.\n",
    "\n",
    "이와 관련된 개념은 [Matrix Factorization Techniques for Recommender Systems](https://endymecy.gitbooks.io/spark-ml-source-analysis/content/%E6%8E%A8%E8%8D%90/papers/Matrix%20Factorization%20Techniques%20for%20Recommender%20Systems.pdf)의 소제목 \"Additional Input Sources\" 내용에 언급되어 있다. side-information을 모델의 학습을 돕기 위해 넣어주는 것인데 예를 들어 아래와 같은 user의 프로필이 있다고 하자. \n",
    "\n",
    "| Feature        | Value           |\n",
    "|:-------------|:-------------|\n",
    "| gender      | Female |\n",
    "| age_bucket      | 25-34      |\n",
    "| income_bucket | $65-79K      |\n",
    "\n",
    "우린 이 정보를 one-hot-encode할 수 있고 각각의 feature들을 $A$라는 \"attribute-space\"에 존재할 것이라고 가정할 수 있다. 그리고 여기에 속한 각각의 attribute인 $a$는 user vector인 $\\textbf{x}_u$와 같이 latent vector $\\textbf{s}_a$를 가진다고 가정하자. 이제 side-information을 기존 user vector에 반영해주면 아래와 같이 user vector를 정의할 수 있다.\n",
    "\n",
    "$\\textbf{x}_u + \\displaystyle \\sum_{a \\in N(u)} \\textbf{s}_a$\n",
    "\n",
    "접근 방법은 간단한데 이걸 기존에 구현했던 방법들에 적용할 경우에 연산량 문제로 인해서 ALS나 SGD에 사용하기 어렵다고 한다. (*왜 그런지는 더 확인 필요.*)\n",
    "\n",
    "그래서 두 가지 다른 방법인 **BPR**와 **WARP**를 소개한다. 아래에서 차례대로 살펴보자.\n",
    "\n",
    "### Learning to Rank - BPR\n",
    "\n",
    "It turns out that there is another method of optimizing implicit feedback matrix factorization problems which is neither ALS nor conventional stochastic gradient descent (SGD) on last post's objective function. This method of optimization typically goes by the name [Learning to Rank](https://en.wikipedia.org/wiki/Learning_to_rank) and originated in information retrieval theory.\n",
    "\n",
    "A classic method of using Learning to Rank with implicit feedback was in the paper [BPR: Bayesian Personalized Ranking from Implicit Feedback](https://arxiv.org/pdf/1205.2618.pdf) (pdf link) first-authored by Steffen Rendle who is kind of a badass in all things implicit and factorized. The idea is centered around sampling *positive* and *negative* items and running pairwise comparisons. Let's assume that for this example our dataset consists of the number of times users have clicked on various items on a website. BPR proceeds as follows (in simplified form):\n",
    "\n",
    "1. Randomly select a user $u$ and then select a random item $i$ which the user has clicked on. This is our *positive* item.\n",
    "2. Randomly select an item $j$ which the user has clicked on $fewer$ times than item $i$ (this includes items that they have never clicked). This is our *negative* item.\n",
    "3. Use whatever equation you want to predict the \"score\", $p_{ui}$, for user $u$ and positive item $i$. For matrix factorization, this may be $\\textbf{x}_{u} \\cdot \\textbf{y}_{i}$.\n",
    "4. Predict the score for user $u$ and negative item $j$, $p_{uj}$.\n",
    "5. Find the difference between the positive and negative scores $x_{uij} = p_{ui} - p_{uj}$.\n",
    "6. Pass this difference through a sigmoid and use it as a weighting for updating all of the model parameters via stochastic gradient descent (SGD).\n",
    "\n",
    "This method seemed kind of radical to me when I first read it. Notably, we do not care about the actual value of the score that we are predicting. All we care about is that we rank items which the user has clicked on more frequently higher than items which the user has clicked on fewer times. And thus, our model \"learns to rank\" :)\n",
    "\n",
    "Because this model employs a sampling-based approach, the authors show that it can be quite fast and scalable relative to other, slower methods. Additionally, the authors argue that BPR directly optimizes the area under the ROC curve (AUC) which could be a desirable characteristic. Most importantly for me, it allows one to easily add in side information without blowing up the computational speed.\n",
    "\n",
    "## Learning to Rank - WARP\n",
    "\n",
    "WARP는 BPR과 비슷하지만 약간 다른 방식을 취한다. user를 정해놓고 positive, negative item을 sampling한다. 그리고 이 둘에 대해서 우리의 모델로 score를 예측을 한다. 이 때, negative item이 positive item보다 score가 높다고 *잘못 예측한 경우*에 대해서만 SGD update를 한다. *잘 예측한 경우* 에는 계속 sampling을 진행하고 전체 item에 대해서 sampling을 해도 되지만 연산량을 고려해서 $N$개를 cutoff value로 지정해놓고 이를 넘을 경우에는 다음 user로 넘어가는 방식이다.\n",
    "\n",
    "WARP에서 추가되는 hyperparameter는 위에서 소개한 **cutoff value** 외에 한 가지가 더 있다. 바로 **margin** 인데 negative item이 positive item보다 score가 얼마나 높을 때를 기준으로 삼느냐를 정하기 위해 사용한다. 논문에선 $p_{uj} > p_{ui} + 1$ 식과 같이 $1$을 margin으로 두었다.\n",
    "\n",
    "sampling 형식으로 학습이 진행되므로 초반에는 *잘못 예측하는 경우* 가 많아서 학습이 빠르게 되지만 시간이 지날 수록 *잘 예측해서* 학습이 느려질 것이라고 예상할 수 있다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 정리 필요 사항\n",
    "\n",
    "1. LightFM 패키지에서 side-information을 어떻게 다루는지: [github](https://github.com/lyst/lightfm/blob/cc43bedbc995594eaf1aba11da4dde4ddb8a8f2a/lightfm/lightfm.py#L124) 소스 코드에 feature matrix를 입력할 때의 내용과 필요 시 identity matrix를 concat하는 방법을 고려하라고 되어 있는데 이 내용이 어떻게 수학적으로 처리가 되는지 모르겠다.\n",
    "2. 학습이 완료되었을 때 item_embedding이 포함하는 값이 tag + item 둘 다인가? 그래서 item/tag 만의 vector를 얻기 위해서 내적을 해줘야 하나? \n",
    "    - tag를 고른 뒤 유사 item을 예측할 때: \n",
    "        - tag vector: item_embeddings에서 tag idx에 해당하는 값 \n",
    "        - item matrix: item_features_concat과 item_embeddings를 내적한 값\n",
    "    - item을 고른 뒤 유사 tag를 예측할 때: \n",
    "        - item vector: item_features_concat에서 item idx에 해당하는 값과 item_embeddings를 내적한 값\n",
    "        - tag matrix: item_embeddings 값 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "from scipy.special import expit\n",
    "import pickle\n",
    "import csv\n",
    "import copy\n",
    "import itertools\n",
    "from lightfm import LightFM\n",
    "import lightfm.evaluation\n",
    "import sys\n",
    "sys.path.append('../utils')\n",
    "import helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 데이터는 user가 item을 봤는지에 대한 데이터(0, 1)이다. 이전 post에서 다룬 데이터와 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelname</th>\n",
       "      <th>mid</th>\n",
       "      <th>uid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3D fanart Noel From Sora no Method</td>\n",
       "      <td>5dcebcfaedbd4e7b8a27bd1ae55f1ac3</td>\n",
       "      <td>7ac1b40648fff523d7220a5d07b04d9b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3D fanart Noel From Sora no Method</td>\n",
       "      <td>5dcebcfaedbd4e7b8a27bd1ae55f1ac3</td>\n",
       "      <td>2b4ad286afe3369d39f1bb7aa2528bc7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3D fanart Noel From Sora no Method</td>\n",
       "      <td>5dcebcfaedbd4e7b8a27bd1ae55f1ac3</td>\n",
       "      <td>1bf0993ebab175a896ac8003bed91b4b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3D fanart Noel From Sora no Method</td>\n",
       "      <td>5dcebcfaedbd4e7b8a27bd1ae55f1ac3</td>\n",
       "      <td>6484211de8b9a023a7d9ab1641d22e7c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3D fanart Noel From Sora no Method</td>\n",
       "      <td>5dcebcfaedbd4e7b8a27bd1ae55f1ac3</td>\n",
       "      <td>1109ee298494fbd192e27878432c718a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            modelname                               mid  \\\n",
       "0  3D fanart Noel From Sora no Method  5dcebcfaedbd4e7b8a27bd1ae55f1ac3   \n",
       "1  3D fanart Noel From Sora no Method  5dcebcfaedbd4e7b8a27bd1ae55f1ac3   \n",
       "2  3D fanart Noel From Sora no Method  5dcebcfaedbd4e7b8a27bd1ae55f1ac3   \n",
       "3  3D fanart Noel From Sora no Method  5dcebcfaedbd4e7b8a27bd1ae55f1ac3   \n",
       "4  3D fanart Noel From Sora no Method  5dcebcfaedbd4e7b8a27bd1ae55f1ac3   \n",
       "\n",
       "                                uid  \n",
       "0  7ac1b40648fff523d7220a5d07b04d9b  \n",
       "1  2b4ad286afe3369d39f1bb7aa2528bc7  \n",
       "2  1bf0993ebab175a896ac8003bed91b4b  \n",
       "3  6484211de8b9a023a7d9ab1641d22e7c  \n",
       "4  1109ee298494fbd192e27878432c718a  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../dataset/model_likes_anon.psv',\n",
    "                 sep='|', quoting=csv.QUOTE_MINIMAL,\n",
    "                 quotechar='\\\\')\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting interactions info\n",
      "Number of rows: 62583\n",
      "Number of cols: 28806\n",
      "Sparsity: 0.035%\n",
      "Ending interactions info\n",
      "Number of rows: 15274\n",
      "Number of columns: 25655\n",
      "Sparsity: 0.140%\n"
     ]
    }
   ],
   "source": [
    "# 전체 데이터 중 5개 이상 평가한 user, 평가 받은 item만 남긴다. sparsity를 올리기 위함이다.\n",
    "df = helpers.threshold_interactions_df(df, 'uid', 'mid', 5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<15274x25655 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 547477 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Go from dataframe to likes matrix\n",
    "# Also, build index to ID mappers.\n",
    "likes, uid_to_idx, idx_to_uid,\\\n",
    "mid_to_idx, idx_to_mid = helpers.df_to_matrix(df, 'uid', 'mid')\n",
    "\n",
    "likes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test, user_index = helpers.train_test_split(likes, 5, fraction=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The one odd thing that we must do which is different than last time is to copy the training data to only include users with data in the test set. This is due to using LightFM's built-in ```precision_at_k``` function as opposed to our hand-rolled one last time and is not particularly interesting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래에서 `user_index`는 test로 뽑힌 user를 나타낸다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eval_train = train.copy()\n",
    "non_eval_users = list(set(range(train.shape[0])) - set(user_index))\n",
    "\n",
    "eval_train = eval_train.tolil()\n",
    "for u in non_eval_users:\n",
    "    eval_train[u, :] = 0.0\n",
    "eval_train = eval_train.tocsr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to one-hot-encode all of the side information that we have about the Sketchfab models. Recall that this information included categories and tags associated with each model. The simplest way I've found to go about encoding this information is to use scikit-learn's [DictVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.DictVectorizer.html) class. The ```DictVectorizer``` takes in a list of dictionaries where the dictionaries contain features names as keys and weights as values. Here, we'll assume that each weight is 1, and we'll take the key to be the combination of the tag type and value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 내용이 뭘 의미하는거지? idx_to_mid에 있는 model 순서대로 tag를 dict에 저장해준다. 그리고 dict들을 list에 모아준다.\n",
    "list니까 자동 sorting 안 일어나서 순서대로 저장된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mid</th>\n",
       "      <th>type</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5dcebcfaedbd4e7b8a27bd1ae55f1ac3</td>\n",
       "      <td>category</td>\n",
       "      <td>Characters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5dcebcfaedbd4e7b8a27bd1ae55f1ac3</td>\n",
       "      <td>category</td>\n",
       "      <td>Gaming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5dcebcfaedbd4e7b8a27bd1ae55f1ac3</td>\n",
       "      <td>tag</td>\n",
       "      <td>3dsmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5dcebcfaedbd4e7b8a27bd1ae55f1ac3</td>\n",
       "      <td>tag</td>\n",
       "      <td>noel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5dcebcfaedbd4e7b8a27bd1ae55f1ac3</td>\n",
       "      <td>tag</td>\n",
       "      <td>loli</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                mid      type       value\n",
       "0  5dcebcfaedbd4e7b8a27bd1ae55f1ac3  category  Characters\n",
       "1  5dcebcfaedbd4e7b8a27bd1ae55f1ac3  category      Gaming\n",
       "2  5dcebcfaedbd4e7b8a27bd1ae55f1ac3       tag      3dsmax\n",
       "3  5dcebcfaedbd4e7b8a27bd1ae55f1ac3       tag        noel\n",
       "4  5dcebcfaedbd4e7b8a27bd1ae55f1ac3       tag        loli"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sideinfo = pd.read_csv('../dataset/model_feats.psv',\n",
    "                       sep='|', quoting=csv.QUOTE_MINIMAL,\n",
    "                       quotechar='\\\\')\n",
    "sideinfo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# There's probably a fancy pandas groupby way to do\n",
    "# this but I couldn't figure it out :(\n",
    "\n",
    "# Build list of dictionaries containing features \n",
    "# and weights in same order as idx_to_mid prescribes.\n",
    "feat_dlist = [{} for _ in idx_to_mid]\n",
    "for idx, row in sideinfo.iterrows():\n",
    "    feat_key = '{}_{}'.format(row.type, str(row.value).lower())\n",
    "    idx = mid_to_idx.get(row.mid)\n",
    "    if idx is not None:\n",
    "        feat_dlist[idx][feat_key] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dv = DictVectorizer()\n",
    "item_features = dv.fit_transform(feat_dlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<25655x20352 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 161510 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model / tag pair 정보이다.\n",
    "item_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now left with an ```item_features``` matrix where each row is a unique item (in the same order as the columns of the ```likes``` matrix), and each column is a unique tag. It looks like there are 20352 unique tags!\n",
    "\n",
    "### Training\n",
    "\n",
    "Let's try a simple WARP run on LightFM using the default settings and ignoring the item features to start. I am only going to focus on WARP today, as I've never had much luck with BPR. I will create a small function to calculate the learning curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_log(row, header=False, spacing=12):\n",
    "    top = ''\n",
    "    middle = ''\n",
    "    bottom = ''\n",
    "    for r in row:\n",
    "        top += '+{}'.format('-'*spacing)\n",
    "        if isinstance(r, str):\n",
    "            middle += '| {0:^{1}} '.format(r, spacing-2)\n",
    "        elif isinstance(r, int):\n",
    "            middle += '| {0:^{1}} '.format(r, spacing-2)\n",
    "        elif (isinstance(r, float)\n",
    "              or isinstance(r, np.float32)\n",
    "              or isinstance(r, np.float64)):\n",
    "            middle += '| {0:^{1}.5f} '.format(r, spacing-2)\n",
    "        bottom += '+{}'.format('='*spacing)\n",
    "    top += '+'\n",
    "    middle += '|'\n",
    "    bottom += '+'\n",
    "    if header:\n",
    "        print(top)\n",
    "        print(middle)\n",
    "        print(bottom)\n",
    "    else:\n",
    "        print(middle)\n",
    "        print(top)\n",
    "\n",
    "def patk_learning_curve(model, train, test, eval_train,\n",
    "                        iterarray, user_features=None,\n",
    "                        item_features=None, k=5,\n",
    "                        **fit_params):\n",
    "    old_epoch = 0\n",
    "    train_patk = []\n",
    "    test_patk = []\n",
    "#     headers = ['Epoch', 'train p@5', 'test p@5']\n",
    "    headers = ['Epoch', 'train auc', 'test auc']\n",
    "    print_log(headers, header=True)\n",
    "    for epoch in iterarray:\n",
    "        more = epoch - old_epoch\n",
    "        model.fit_partial(train, user_features=user_features,\n",
    "                          item_features=item_features,\n",
    "                          epochs=more, **fit_params)\n",
    "        this_test = lightfm.evaluation.auc_score(model, test, train_interactions=None)\n",
    "        this_train = lightfm.evaluation.auc_score(model, eval_train, train_interactions=None)\n",
    "\n",
    "        train_patk.append(np.mean(this_train))\n",
    "        test_patk.append(np.mean(this_test))\n",
    "        row = [epoch, train_patk[-1], test_patk[-1]]\n",
    "        print_log(row)\n",
    "    return model, train_patk, test_patk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+------------+\n",
      "|   Epoch    | train auc  |  test auc  |\n",
      "+============+============+============+\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Incorrect number of features in item_features",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-b8259d1a9259>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m model, train_patk, test_patk = patk_learning_curve(\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mitem_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'num_threads'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m )\n",
      "\u001b[0;32m<ipython-input-40-90f5236b3435>\u001b[0m in \u001b[0;36mpatk_learning_curve\u001b[0;34m(model, train, test, eval_train, iterarray, user_features, item_features, k, **fit_params)\u001b[0m\n\u001b[1;32m     39\u001b[0m         model.fit_partial(train, user_features=user_features,\n\u001b[1;32m     40\u001b[0m                           \u001b[0mitem_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mitem_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m                           epochs=more, **fit_params)\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mthis_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlightfm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_interactions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mthis_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlightfm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_interactions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/whikwon/anaconda3/lib/python3.6/site-packages/lightfm/lightfm.py\u001b[0m in \u001b[0;36mfit_partial\u001b[0;34m(self, interactions, user_features, item_features, sample_weight, epochs, num_threads, verbose)\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;31m# not changed between runs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mitem_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Incorrect number of features in item_features'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0muser_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Incorrect number of features in item_features"
     ]
    }
   ],
   "source": [
    "model = LightFM(loss='warp', random_state=2016)\n",
    "# Initialize model.\n",
    "model.fit(train, epochs=0);\n",
    "\n",
    "iterarray = range(10, 110, 10)\n",
    "\n",
    "model, train_patk, test_patk = patk_learning_curve(\n",
    "    model, train, test, eval_train, iterarray, item_features=item_features, k=5, **{'num_threads': 4}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'iterarray' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-dcd56b23ca98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdespine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m plot_patk(iterarray, train_patk,\n\u001b[0m\u001b[1;32m     18\u001b[0m          'Train', k=5)\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'iterarray' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPUAAAFOCAYAAABey1tnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5037321198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "\n",
    "def plot_patk(iterarray, patk,\n",
    "              title, k=5):\n",
    "    plt.plot(iterarray, patk);\n",
    "    plt.title(title, fontsize=20);\n",
    "    plt.xlabel('Epochs', fontsize=24);\n",
    "    plt.ylabel('p@{}'.format(k), fontsize=24);\n",
    "    plt.xticks(fontsize=14);\n",
    "    plt.yticks(fontsize=14);\n",
    "\n",
    "# Plot train on left\n",
    "ax = plt.subplot(1, 2, 1)\n",
    "fig = ax.get_figure();\n",
    "sns.despine(fig);\n",
    "plot_patk(iterarray, train_patk,\n",
    "         'Train', k=5)\n",
    "\n",
    "# Plot test on right\n",
    "ax = plt.subplot(1, 2, 2)\n",
    "fig = ax.get_figure();\n",
    "sns.despine(fig);\n",
    "plot_patk(iterarray, test_patk,\n",
    "         'Test', k=5)\n",
    "\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing Hyperparameters with ```scikit-optimize```\n",
    "\n",
    "Now that we have a baseline, we would like to find optimal hyperparameters to maximize our p@k. On a side note, I'm not sure if precision at k is the best metric to be using here when all of our interactions are binary, but let's just ignore that for now...\n",
    "\n",
    "Last post I ran a grid search over a bunch of hyperparameters, and it took forever. It's been shown that a randomized search is better than explicit grid search, but we can do even better. Using the [scikit-optimize](https://scikit-optimize.github.io/) (```skopt```) library, we can treat the hyperpameters as free parameters to search over while using a black box optimization algorithm to maximize p@k. There are a number of optimization algorithms to pick from, but I'll just stick with ```forest_minimize``` today.\n",
    "\n",
    "The setup is pretty simple. You must first define an objective function that you want to minimize. The objective receives the parameters that you want to solve for as the arguments and returns the objective value at those parameters. Thus, for our case, we pass in the hyperparameters, we train the ```LightFM``` model with those parameters, and then return the p@k evaluated after training. Importantly, we must return the negative of the p@k because the objective must be *minimized*, so maximizing p@k is the same as minimizing the negative of the p@k. The last thing to note is that one must make liberal use of global variables because one can only pass hyperparameters to the objective function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skopt import forest_minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    # unpack\n",
    "    epochs, learning_rate,\\\n",
    "    no_components, alpha = params\n",
    "    \n",
    "    user_alpha = alpha\n",
    "    item_alpha = alpha\n",
    "    model = LightFM(loss='warp',\n",
    "                    random_state=2016,\n",
    "                    learning_rate=learning_rate,\n",
    "                    no_components=no_components,\n",
    "                    user_alpha=user_alpha,\n",
    "                    item_alpha=item_alpha)\n",
    "    model.fit(train, epochs=epochs,\n",
    "              num_threads=4, verbose=True)\n",
    "    \n",
    "    patks = lightfm.evaluation.precision_at_k(model, test,\n",
    "                                              train_interactions=None,\n",
    "                                              k=5, num_threads=4)\n",
    "    mapatk = np.mean(patks)\n",
    "    # Make negative because we want to _minimize_ objective\n",
    "    out = -mapatk\n",
    "    # Handle some weird numerical shit going on\n",
    "    if np.abs(out + 1) < 0.01 or out < -1.0:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the objective function defined, we can define ranges for our hyperparameters. These can either be simple max and mins or we can assume a distribution like below. With the ranges defined, we simple call ```forest_minimize``` and wait a pretty long time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 1 started. Evaluating function at random point.\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n",
      "Epoch 30\n",
      "Epoch 31\n",
      "Epoch 32\n",
      "Epoch 33\n",
      "Epoch 34\n",
      "Epoch 35\n",
      "Epoch 36\n",
      "Epoch 37\n",
      "Epoch 38\n",
      "Epoch 39\n",
      "Epoch 40\n",
      "Epoch 41\n",
      "Epoch 42\n",
      "Epoch 43\n",
      "Epoch 44\n",
      "Epoch 45\n",
      "Epoch 46\n",
      "Epoch 47\n",
      "Epoch 48\n",
      "Epoch 49\n",
      "Epoch 50\n",
      "Epoch 51\n",
      "Epoch 52\n",
      "Epoch 53\n",
      "Epoch 54\n",
      "Epoch 55\n",
      "Epoch 56\n",
      "Epoch 57\n",
      "Epoch 58\n",
      "Epoch 59\n",
      "Epoch 60\n",
      "Epoch 61\n",
      "Epoch 62\n",
      "Epoch 63\n",
      "Epoch 64\n",
      "Epoch 65\n",
      "Epoch 66\n",
      "Epoch 67\n",
      "Epoch 68\n",
      "Epoch 69\n",
      "Epoch 70\n",
      "Epoch 71\n",
      "Epoch 72\n",
      "Epoch 73\n",
      "Epoch 74\n",
      "Epoch 75\n",
      "Epoch 76\n",
      "Epoch 77\n",
      "Epoch 78\n",
      "Epoch 79\n",
      "Epoch 80\n",
      "Epoch 81\n",
      "Epoch 82\n",
      "Epoch 83\n",
      "Epoch 84\n",
      "Epoch 85\n",
      "Epoch 86\n",
      "Epoch 87\n",
      "Epoch 88\n",
      "Epoch 89\n",
      "Epoch 90\n",
      "Epoch 91\n",
      "Epoch 92\n",
      "Epoch 93\n",
      "Epoch 94\n",
      "Epoch 95\n",
      "Epoch 96\n",
      "Epoch 97\n",
      "Epoch 98\n",
      "Epoch 99\n",
      "Epoch 100\n",
      "Epoch 101\n",
      "Epoch 102\n",
      "Epoch 103\n",
      "Epoch 104\n",
      "Epoch 105\n",
      "Epoch 106\n",
      "Epoch 107\n",
      "Epoch 108\n",
      "Epoch 109\n",
      "Epoch 110\n",
      "Epoch 111\n",
      "Epoch 112\n",
      "Epoch 113\n",
      "Epoch 114\n",
      "Epoch 115\n",
      "Epoch 116\n",
      "Epoch 117\n",
      "Epoch 118\n",
      "Epoch 119\n",
      "Epoch 120\n",
      "Epoch 121\n",
      "Epoch 122\n",
      "Epoch 123\n",
      "Epoch 124\n",
      "Epoch 125\n",
      "Epoch 126\n",
      "Epoch 127\n",
      "Epoch 128\n",
      "Epoch 129\n",
      "Epoch 130\n",
      "Epoch 131\n",
      "Epoch 132\n",
      "Epoch 133\n",
      "Epoch 134\n",
      "Epoch 135\n",
      "Epoch 136\n",
      "Epoch 137\n",
      "Epoch 138\n",
      "Epoch 139\n",
      "Epoch 140\n",
      "Epoch 141\n",
      "Epoch 142\n",
      "Epoch 143\n",
      "Epoch 144\n",
      "Epoch 145\n",
      "Epoch 146\n",
      "Epoch 147\n",
      "Epoch 148\n",
      "Epoch 149\n",
      "Epoch 150\n",
      "Epoch 151\n",
      "Epoch 152\n",
      "Epoch 153\n",
      "Epoch 154\n",
      "Epoch 155\n",
      "Epoch 156\n",
      "Epoch 157\n",
      "Epoch 158\n",
      "Epoch 159\n",
      "Epoch 160\n",
      "Epoch 161\n",
      "Epoch 162\n",
      "Epoch 163\n",
      "Epoch 164\n",
      "Epoch 165\n",
      "Epoch 166\n",
      "Epoch 167\n",
      "Epoch 168\n",
      "Epoch 169\n",
      "Epoch 170\n",
      "Epoch 171\n",
      "Epoch 172\n",
      "Iteration No: 1 ended. Evaluation done at random point.\n",
      "Time taken: 103.9011\n",
      "Function value obtained: -0.0001\n",
      "Current minimum: -0.0001\n",
      "Iteration No: 2 started. Evaluating function at random point.\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Iteration No: 2 ended. Evaluation done at random point.\n",
      "Time taken: 5.7961\n",
      "Function value obtained: -0.0289\n",
      "Current minimum: -0.0289\n",
      "Iteration No: 3 started. Evaluating function at random point.\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n",
      "Epoch 30\n",
      "Epoch 31\n",
      "Epoch 32\n",
      "Epoch 33\n",
      "Epoch 34\n",
      "Epoch 35\n",
      "Epoch 36\n",
      "Epoch 37\n",
      "Epoch 38\n",
      "Epoch 39\n",
      "Epoch 40\n",
      "Epoch 41\n",
      "Epoch 42\n",
      "Epoch 43\n",
      "Epoch 44\n",
      "Epoch 45\n",
      "Epoch 46\n",
      "Epoch 47\n",
      "Epoch 48\n",
      "Epoch 49\n",
      "Epoch 50\n",
      "Epoch 51\n",
      "Epoch 52\n",
      "Epoch 53\n",
      "Epoch 54\n",
      "Epoch 55\n",
      "Epoch 56\n",
      "Epoch 57\n",
      "Epoch 58\n",
      "Epoch 59\n",
      "Epoch 60\n",
      "Epoch 61\n",
      "Epoch 62\n",
      "Epoch 63\n",
      "Epoch 64\n",
      "Epoch 65\n",
      "Epoch 66\n",
      "Epoch 67\n",
      "Epoch 68\n",
      "Epoch 69\n",
      "Epoch 70\n",
      "Epoch 71\n",
      "Epoch 72\n",
      "Epoch 73\n",
      "Epoch 74\n",
      "Epoch 75\n",
      "Epoch 76\n",
      "Epoch 77\n",
      "Epoch 78\n",
      "Epoch 79\n",
      "Epoch 80\n",
      "Epoch 81\n",
      "Epoch 82\n",
      "Epoch 83\n",
      "Epoch 84\n",
      "Epoch 85\n",
      "Epoch 86\n",
      "Epoch 87\n",
      "Epoch 88\n",
      "Iteration No: 3 ended. Evaluation done at random point.\n",
      "Time taken: 38.9033\n",
      "Function value obtained: -0.0148\n",
      "Current minimum: -0.0289\n",
      "Iteration No: 4 started. Evaluating function at random point.\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n",
      "Epoch 30\n",
      "Epoch 31\n",
      "Epoch 32\n",
      "Epoch 33\n",
      "Epoch 34\n",
      "Epoch 35\n",
      "Epoch 36\n",
      "Epoch 37\n",
      "Epoch 38\n",
      "Epoch 39\n",
      "Epoch 40\n",
      "Epoch 41\n",
      "Epoch 42\n",
      "Epoch 43\n",
      "Epoch 44\n",
      "Epoch 45\n",
      "Epoch 46\n",
      "Epoch 47\n",
      "Epoch 48\n",
      "Epoch 49\n",
      "Epoch 50\n",
      "Epoch 51\n",
      "Epoch 52\n",
      "Epoch 53\n",
      "Epoch 54\n",
      "Epoch 55\n",
      "Epoch 56\n",
      "Epoch 57\n",
      "Epoch 58\n",
      "Epoch 59\n",
      "Epoch 60\n",
      "Epoch 61\n",
      "Epoch 62\n",
      "Epoch 63\n",
      "Epoch 64\n",
      "Epoch 65\n",
      "Epoch 66\n",
      "Epoch 67\n",
      "Epoch 68\n",
      "Epoch 69\n",
      "Epoch 70\n",
      "Epoch 71\n",
      "Epoch 72\n",
      "Epoch 73\n",
      "Epoch 74\n",
      "Epoch 75\n",
      "Epoch 76\n",
      "Epoch 77\n",
      "Epoch 78\n",
      "Epoch 79\n",
      "Epoch 80\n",
      "Epoch 81\n",
      "Epoch 82\n",
      "Epoch 83\n",
      "Epoch 84\n",
      "Epoch 85\n",
      "Epoch 86\n",
      "Epoch 87\n",
      "Epoch 88\n",
      "Iteration No: 4 ended. Evaluation done at random point.\n",
      "Time taken: 32.4974\n",
      "Function value obtained: -0.0195\n",
      "Current minimum: -0.0289\n",
      "Iteration No: 5 started. Evaluating function at random point.\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n",
      "Epoch 30\n",
      "Epoch 31\n",
      "Epoch 32\n",
      "Epoch 33\n",
      "Epoch 34\n",
      "Epoch 35\n",
      "Epoch 36\n",
      "Epoch 37\n",
      "Epoch 38\n",
      "Epoch 39\n",
      "Epoch 40\n",
      "Epoch 41\n",
      "Epoch 42\n",
      "Epoch 43\n",
      "Epoch 44\n",
      "Epoch 45\n",
      "Epoch 46\n",
      "Epoch 47\n",
      "Epoch 48\n",
      "Epoch 49\n",
      "Epoch 50\n",
      "Epoch 51\n",
      "Epoch 52\n",
      "Epoch 53\n",
      "Epoch 54\n",
      "Epoch 55\n",
      "Epoch 56\n",
      "Epoch 57\n",
      "Epoch 58\n",
      "Epoch 59\n",
      "Epoch 60\n",
      "Epoch 61\n",
      "Epoch 62\n",
      "Epoch 63\n",
      "Epoch 64\n",
      "Epoch 65\n",
      "Epoch 66\n",
      "Epoch 67\n",
      "Epoch 68\n",
      "Epoch 69\n",
      "Epoch 70\n",
      "Epoch 71\n",
      "Epoch 72\n",
      "Epoch 73\n",
      "Epoch 74\n",
      "Epoch 75\n",
      "Epoch 76\n",
      "Epoch 77\n",
      "Epoch 78\n",
      "Epoch 79\n",
      "Epoch 80\n",
      "Epoch 81\n",
      "Epoch 82\n",
      "Epoch 83\n",
      "Epoch 84\n",
      "Epoch 85\n",
      "Epoch 86\n",
      "Epoch 87\n",
      "Epoch 88\n",
      "Epoch 89\n",
      "Epoch 90\n",
      "Epoch 91\n",
      "Epoch 92\n",
      "Epoch 93\n",
      "Epoch 94\n",
      "Epoch 95\n",
      "Epoch 96\n",
      "Epoch 97\n",
      "Epoch 98\n",
      "Epoch 99\n",
      "Epoch 100\n",
      "Epoch 101\n",
      "Epoch 102\n",
      "Epoch 103\n",
      "Epoch 104\n",
      "Epoch 105\n",
      "Epoch 106\n",
      "Epoch 107\n",
      "Epoch 108\n",
      "Epoch 109\n",
      "Epoch 110\n",
      "Epoch 111\n",
      "Epoch 112\n",
      "Epoch 113\n",
      "Epoch 114\n",
      "Epoch 115\n",
      "Iteration No: 5 ended. Evaluation done at random point.\n",
      "Time taken: 72.1895\n",
      "Function value obtained: -0.0136\n",
      "Current minimum: -0.0289\n",
      "Iteration No: 6 started. Evaluating function at random point.\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n",
      "Epoch 30\n",
      "Epoch 31\n",
      "Epoch 32\n",
      "Epoch 33\n",
      "Epoch 34\n",
      "Epoch 35\n",
      "Epoch 36\n",
      "Epoch 37\n",
      "Epoch 38\n",
      "Epoch 39\n",
      "Epoch 40\n",
      "Epoch 41\n",
      "Epoch 42\n",
      "Epoch 43\n",
      "Epoch 44\n",
      "Epoch 45\n",
      "Epoch 46\n",
      "Epoch 47\n",
      "Epoch 48\n",
      "Epoch 49\n",
      "Epoch 50\n",
      "Epoch 51\n",
      "Epoch 52\n",
      "Epoch 53\n",
      "Epoch 54\n",
      "Epoch 55\n",
      "Epoch 56\n",
      "Epoch 57\n",
      "Epoch 58\n",
      "Epoch 59\n",
      "Epoch 60\n",
      "Epoch 61\n",
      "Epoch 62\n",
      "Epoch 63\n",
      "Epoch 64\n",
      "Epoch 65\n",
      "Epoch 66\n",
      "Epoch 67\n",
      "Epoch 68\n",
      "Epoch 69\n",
      "Epoch 70\n",
      "Epoch 71\n",
      "Epoch 72\n",
      "Epoch 73\n",
      "Epoch 74\n",
      "Epoch 75\n",
      "Epoch 76\n",
      "Epoch 77\n",
      "Epoch 78\n",
      "Epoch 79\n",
      "Epoch 80\n",
      "Epoch 81\n",
      "Epoch 82\n",
      "Epoch 83\n",
      "Epoch 84\n",
      "Epoch 85\n",
      "Epoch 86\n",
      "Epoch 87\n",
      "Epoch 88\n",
      "Epoch 89\n",
      "Epoch 90\n",
      "Epoch 91\n",
      "Epoch 92\n",
      "Epoch 93\n",
      "Epoch 94\n",
      "Epoch 95\n",
      "Epoch 96\n",
      "Epoch 97\n",
      "Epoch 98\n",
      "Epoch 99\n",
      "Iteration No: 6 ended. Evaluation done at random point.\n",
      "Time taken: 37.7232\n",
      "Function value obtained: -0.0000\n",
      "Current minimum: -0.0289\n",
      "Iteration No: 7 started. Evaluating function at random point.\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n",
      "Epoch 30\n",
      "Epoch 31\n",
      "Epoch 32\n",
      "Epoch 33\n",
      "Epoch 34\n",
      "Epoch 35\n",
      "Epoch 36\n",
      "Epoch 37\n",
      "Epoch 38\n",
      "Epoch 39\n",
      "Epoch 40\n",
      "Epoch 41\n",
      "Epoch 42\n",
      "Epoch 43\n",
      "Epoch 44\n",
      "Epoch 45\n",
      "Epoch 46\n",
      "Epoch 47\n",
      "Epoch 48\n",
      "Epoch 49\n",
      "Epoch 50\n",
      "Epoch 51\n",
      "Epoch 52\n",
      "Epoch 53\n",
      "Epoch 54\n",
      "Epoch 55\n",
      "Epoch 56\n",
      "Epoch 57\n",
      "Epoch 58\n",
      "Epoch 59\n",
      "Epoch 60\n",
      "Epoch 61\n",
      "Epoch 62\n",
      "Epoch 63\n",
      "Epoch 64\n",
      "Epoch 65\n",
      "Epoch 66\n",
      "Epoch 67\n",
      "Epoch 68\n",
      "Epoch 69\n",
      "Epoch 70\n",
      "Epoch 71\n",
      "Epoch 72\n",
      "Epoch 73\n",
      "Epoch 74\n",
      "Epoch 75\n",
      "Epoch 76\n",
      "Epoch 77\n",
      "Epoch 78\n",
      "Epoch 79\n",
      "Epoch 80\n",
      "Epoch 81\n",
      "Epoch 82\n",
      "Epoch 83\n",
      "Epoch 84\n",
      "Epoch 85\n",
      "Epoch 86\n",
      "Epoch 87\n",
      "Epoch 88\n",
      "Epoch 89\n",
      "Epoch 90\n",
      "Epoch 91\n",
      "Epoch 92\n",
      "Epoch 93\n",
      "Epoch 94\n",
      "Epoch 95\n",
      "Epoch 96\n",
      "Epoch 97\n",
      "Epoch 98\n",
      "Epoch 99\n",
      "Epoch 100\n",
      "Epoch 101\n",
      "Epoch 102\n",
      "Epoch 103\n",
      "Epoch 104\n",
      "Epoch 105\n",
      "Epoch 106\n",
      "Epoch 107\n",
      "Epoch 108\n",
      "Epoch 109\n",
      "Epoch 110\n",
      "Epoch 111\n",
      "Epoch 112\n",
      "Epoch 113\n",
      "Epoch 114\n",
      "Epoch 115\n",
      "Epoch 116\n",
      "Epoch 117\n",
      "Epoch 118\n",
      "Epoch 119\n",
      "Epoch 120\n",
      "Epoch 121\n",
      "Epoch 122\n",
      "Epoch 123\n",
      "Epoch 124\n",
      "Epoch 125\n",
      "Epoch 126\n",
      "Epoch 127\n",
      "Epoch 128\n",
      "Epoch 129\n",
      "Epoch 130\n",
      "Epoch 131\n",
      "Epoch 132\n",
      "Epoch 133\n",
      "Epoch 134\n",
      "Epoch 135\n",
      "Epoch 136\n",
      "Epoch 137\n",
      "Epoch 138\n",
      "Epoch 139\n",
      "Epoch 140\n",
      "Epoch 141\n",
      "Epoch 142\n",
      "Epoch 143\n",
      "Epoch 144\n",
      "Epoch 145\n",
      "Epoch 146\n",
      "Epoch 147\n",
      "Epoch 148\n",
      "Epoch 149\n",
      "Epoch 150\n",
      "Epoch 151\n",
      "Epoch 152\n",
      "Epoch 153\n",
      "Epoch 154\n",
      "Epoch 155\n",
      "Epoch 156\n",
      "Epoch 157\n",
      "Epoch 158\n",
      "Epoch 159\n",
      "Epoch 160\n",
      "Epoch 161\n",
      "Epoch 162\n",
      "Epoch 163\n",
      "Epoch 164\n",
      "Epoch 165\n",
      "Epoch 166\n",
      "Epoch 167\n",
      "Epoch 168\n",
      "Epoch 169\n",
      "Epoch 170\n",
      "Epoch 171\n",
      "Epoch 172\n",
      "Epoch 173\n",
      "Epoch 174\n",
      "Epoch 175\n",
      "Epoch 176\n",
      "Epoch 177\n",
      "Epoch 178\n",
      "Epoch 179\n",
      "Epoch 180\n",
      "Epoch 181\n",
      "Epoch 182\n",
      "Epoch 183\n",
      "Epoch 184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 185\n",
      "Iteration No: 7 ended. Evaluation done at random point.\n",
      "Time taken: 74.2577\n",
      "Function value obtained: -0.0003\n",
      "Current minimum: -0.0289\n",
      "Iteration No: 8 started. Evaluating function at random point.\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n",
      "Epoch 30\n",
      "Epoch 31\n",
      "Epoch 32\n",
      "Epoch 33\n",
      "Epoch 34\n",
      "Epoch 35\n",
      "Epoch 36\n",
      "Epoch 37\n",
      "Epoch 38\n",
      "Epoch 39\n",
      "Epoch 40\n",
      "Epoch 41\n",
      "Epoch 42\n",
      "Epoch 43\n",
      "Epoch 44\n",
      "Epoch 45\n",
      "Epoch 46\n",
      "Epoch 47\n",
      "Epoch 48\n",
      "Epoch 49\n",
      "Epoch 50\n",
      "Epoch 51\n",
      "Epoch 52\n",
      "Epoch 53\n",
      "Epoch 54\n",
      "Epoch 55\n",
      "Epoch 56\n",
      "Epoch 57\n",
      "Epoch 58\n",
      "Epoch 59\n",
      "Epoch 60\n",
      "Epoch 61\n",
      "Epoch 62\n",
      "Epoch 63\n",
      "Epoch 64\n",
      "Epoch 65\n",
      "Epoch 66\n",
      "Epoch 67\n",
      "Epoch 68\n",
      "Epoch 69\n",
      "Epoch 70\n",
      "Epoch 71\n",
      "Epoch 72\n",
      "Epoch 73\n",
      "Epoch 74\n",
      "Epoch 75\n",
      "Epoch 76\n",
      "Epoch 77\n",
      "Epoch 78\n",
      "Epoch 79\n",
      "Epoch 80\n",
      "Epoch 81\n",
      "Epoch 82\n",
      "Epoch 83\n",
      "Epoch 84\n",
      "Epoch 85\n",
      "Epoch 86\n",
      "Epoch 87\n",
      "Epoch 88\n",
      "Epoch 89\n",
      "Epoch 90\n",
      "Epoch 91\n",
      "Epoch 92\n",
      "Epoch 93\n",
      "Epoch 94\n",
      "Epoch 95\n",
      "Epoch 96\n",
      "Epoch 97\n",
      "Epoch 98\n",
      "Epoch 99\n",
      "Epoch 100\n",
      "Epoch 101\n",
      "Epoch 102\n",
      "Epoch 103\n",
      "Epoch 104\n",
      "Epoch 105\n",
      "Epoch 106\n",
      "Epoch 107\n",
      "Epoch 108\n",
      "Epoch 109\n",
      "Epoch 110\n",
      "Epoch 111\n",
      "Epoch 112\n",
      "Epoch 113\n",
      "Epoch 114\n",
      "Epoch 115\n",
      "Epoch 116\n",
      "Epoch 117\n",
      "Epoch 118\n",
      "Epoch 119\n",
      "Epoch 120\n",
      "Epoch 121\n",
      "Epoch 122\n",
      "Epoch 123\n",
      "Epoch 124\n",
      "Epoch 125\n",
      "Epoch 126\n",
      "Epoch 127\n",
      "Epoch 128\n",
      "Epoch 129\n",
      "Epoch 130\n",
      "Epoch 131\n",
      "Epoch 132\n",
      "Epoch 133\n",
      "Epoch 134\n",
      "Epoch 135\n",
      "Epoch 136\n",
      "Epoch 137\n",
      "Epoch 138\n",
      "Epoch 139\n",
      "Epoch 140\n",
      "Epoch 141\n",
      "Epoch 142\n",
      "Epoch 143\n",
      "Epoch 144\n",
      "Epoch 145\n",
      "Epoch 146\n",
      "Epoch 147\n",
      "Epoch 148\n",
      "Epoch 149\n",
      "Epoch 150\n",
      "Epoch 151\n",
      "Iteration No: 8 ended. Evaluation done at random point.\n",
      "Time taken: 116.6162\n",
      "Function value obtained: -0.0154\n",
      "Current minimum: -0.0289\n",
      "Iteration No: 9 started. Evaluating function at random point.\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n",
      "Epoch 30\n",
      "Epoch 31\n",
      "Epoch 32\n",
      "Epoch 33\n",
      "Epoch 34\n",
      "Epoch 35\n",
      "Epoch 36\n",
      "Epoch 37\n",
      "Epoch 38\n",
      "Epoch 39\n",
      "Epoch 40\n",
      "Epoch 41\n",
      "Epoch 42\n",
      "Epoch 43\n",
      "Epoch 44\n",
      "Epoch 45\n",
      "Epoch 46\n",
      "Epoch 47\n",
      "Epoch 48\n",
      "Epoch 49\n",
      "Epoch 50\n",
      "Epoch 51\n",
      "Epoch 52\n",
      "Epoch 53\n",
      "Epoch 54\n",
      "Epoch 55\n",
      "Epoch 56\n",
      "Epoch 57\n",
      "Epoch 58\n",
      "Epoch 59\n",
      "Epoch 60\n",
      "Epoch 61\n",
      "Epoch 62\n",
      "Epoch 63\n",
      "Epoch 64\n",
      "Epoch 65\n",
      "Epoch 66\n",
      "Epoch 67\n",
      "Epoch 68\n",
      "Epoch 69\n",
      "Epoch 70\n",
      "Epoch 71\n",
      "Epoch 72\n",
      "Epoch 73\n",
      "Epoch 74\n",
      "Epoch 75\n",
      "Epoch 76\n",
      "Epoch 77\n",
      "Epoch 78\n",
      "Epoch 79\n",
      "Epoch 80\n",
      "Epoch 81\n",
      "Epoch 82\n",
      "Epoch 83\n",
      "Epoch 84\n",
      "Epoch 85\n",
      "Epoch 86\n",
      "Epoch 87\n",
      "Epoch 88\n",
      "Epoch 89\n",
      "Epoch 90\n",
      "Epoch 91\n",
      "Epoch 92\n",
      "Epoch 93\n",
      "Epoch 94\n",
      "Epoch 95\n",
      "Epoch 96\n",
      "Epoch 97\n",
      "Epoch 98\n",
      "Epoch 99\n",
      "Epoch 100\n",
      "Epoch 101\n",
      "Epoch 102\n",
      "Epoch 103\n",
      "Epoch 104\n",
      "Epoch 105\n",
      "Epoch 106\n",
      "Epoch 107\n",
      "Epoch 108\n",
      "Epoch 109\n",
      "Epoch 110\n",
      "Epoch 111\n",
      "Epoch 112\n",
      "Epoch 113\n",
      "Epoch 114\n",
      "Epoch 115\n",
      "Epoch 116\n",
      "Epoch 117\n",
      "Epoch 118\n",
      "Epoch 119\n",
      "Epoch 120\n",
      "Epoch 121\n",
      "Epoch 122\n",
      "Epoch 123\n",
      "Epoch 124\n",
      "Epoch 125\n",
      "Epoch 126\n",
      "Epoch 127\n",
      "Epoch 128\n",
      "Iteration No: 9 ended. Evaluation done at random point.\n",
      "Time taken: 60.4377\n",
      "Function value obtained: -0.0138\n",
      "Current minimum: -0.0289\n",
      "Iteration No: 10 started. Evaluating function at random point.\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n",
      "Epoch 30\n",
      "Epoch 31\n",
      "Epoch 32\n",
      "Epoch 33\n",
      "Epoch 34\n",
      "Epoch 35\n",
      "Epoch 36\n",
      "Epoch 37\n",
      "Epoch 38\n",
      "Epoch 39\n",
      "Epoch 40\n",
      "Epoch 41\n",
      "Epoch 42\n",
      "Epoch 43\n",
      "Epoch 44\n",
      "Epoch 45\n",
      "Epoch 46\n",
      "Epoch 47\n",
      "Epoch 48\n",
      "Epoch 49\n",
      "Epoch 50\n",
      "Epoch 51\n",
      "Epoch 52\n",
      "Epoch 53\n",
      "Epoch 54\n",
      "Epoch 55\n",
      "Epoch 56\n",
      "Epoch 57\n",
      "Epoch 58\n",
      "Epoch 59\n",
      "Epoch 60\n",
      "Epoch 61\n",
      "Epoch 62\n",
      "Epoch 63\n",
      "Epoch 64\n",
      "Epoch 65\n",
      "Epoch 66\n",
      "Epoch 67\n",
      "Epoch 68\n",
      "Epoch 69\n",
      "Epoch 70\n",
      "Epoch 71\n",
      "Epoch 72\n",
      "Epoch 73\n",
      "Epoch 74\n",
      "Epoch 75\n",
      "Epoch 76\n",
      "Epoch 77\n",
      "Epoch 78\n",
      "Epoch 79\n",
      "Epoch 80\n",
      "Epoch 81\n",
      "Epoch 82\n",
      "Epoch 83\n",
      "Epoch 84\n",
      "Epoch 85\n",
      "Epoch 86\n",
      "Epoch 87\n",
      "Epoch 88\n",
      "Epoch 89\n",
      "Epoch 90\n",
      "Epoch 91\n",
      "Epoch 92\n",
      "Epoch 93\n",
      "Epoch 94\n",
      "Epoch 95\n",
      "Epoch 96\n",
      "Epoch 97\n",
      "Epoch 98\n",
      "Epoch 99\n",
      "Epoch 100\n",
      "Epoch 101\n",
      "Epoch 102\n",
      "Epoch 103\n",
      "Epoch 104\n",
      "Epoch 105\n",
      "Epoch 106\n",
      "Epoch 107\n",
      "Epoch 108\n",
      "Epoch 109\n",
      "Epoch 110\n",
      "Epoch 111\n",
      "Epoch 112\n",
      "Epoch 113\n",
      "Epoch 114\n",
      "Epoch 115\n",
      "Epoch 116\n",
      "Epoch 117\n",
      "Epoch 118\n",
      "Epoch 119\n",
      "Epoch 120\n",
      "Epoch 121\n",
      "Epoch 122\n",
      "Epoch 123\n",
      "Epoch 124\n",
      "Epoch 125\n",
      "Epoch 126\n",
      "Epoch 127\n",
      "Epoch 128\n",
      "Epoch 129\n",
      "Epoch 130\n",
      "Epoch 131\n",
      "Epoch 132\n",
      "Epoch 133\n",
      "Epoch 134\n",
      "Epoch 135\n",
      "Epoch 136\n",
      "Epoch 137\n",
      "Epoch 138\n",
      "Epoch 139\n",
      "Epoch 140\n",
      "Epoch 141\n",
      "Epoch 142\n",
      "Epoch 143\n",
      "Epoch 144\n",
      "Epoch 145\n",
      "Epoch 146\n",
      "Epoch 147\n",
      "Epoch 148\n",
      "Epoch 149\n",
      "Epoch 150\n",
      "Epoch 151\n",
      "Epoch 152\n",
      "Epoch 153\n",
      "Epoch 154\n",
      "Epoch 155\n",
      "Epoch 156\n",
      "Epoch 157\n",
      "Epoch 158\n",
      "Epoch 159\n",
      "Epoch 160\n",
      "Epoch 161\n",
      "Epoch 162\n",
      "Epoch 163\n",
      "Epoch 164\n",
      "Epoch 165\n",
      "Epoch 166\n",
      "Epoch 167\n",
      "Epoch 168\n",
      "Epoch 169\n",
      "Epoch 170\n",
      "Epoch 171\n",
      "Epoch 172\n",
      "Epoch 173\n",
      "Epoch 174\n",
      "Epoch 175\n",
      "Epoch 176\n",
      "Epoch 177\n",
      "Epoch 178\n",
      "Epoch 179\n",
      "Epoch 180\n",
      "Epoch 181\n",
      "Epoch 182\n",
      "Epoch 183\n",
      "Epoch 184\n",
      "Epoch 185\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-97b7fe9692ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m res_fm = forest_minimize(objective, space, n_calls=250,\n\u001b[1;32m      8\u001b[0m                      \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                      verbose=True)\n\u001b[0m",
      "\u001b[0;32m/home/whikwon/anaconda3/lib/python3.6/site-packages/skopt/optimizer/forest.py\u001b[0m in \u001b[0;36mforest_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, acq_func, x0, y0, random_state, verbose, callback, n_points, xi, kappa, n_jobs)\u001b[0m\n\u001b[1;32m    160\u001b[0m                          \u001b[0macq_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0macq_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m                          \u001b[0mxi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkappa\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkappa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m                          callback=callback, acq_optimizer=\"sampling\")\n\u001b[0m",
      "\u001b[0;32m/home/whikwon/anaconda3/lib/python3.6/site-packages/skopt/optimizer/base.py\u001b[0m in \u001b[0;36mbase_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, n_jobs)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;31m# no need to fit a model on the last iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0mfit_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mn_calls\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m         \u001b[0mnext_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspecs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-a6a43cb5090f>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m     12\u001b[0m                     item_alpha=item_alpha)\n\u001b[1;32m     13\u001b[0m     model.fit(train, epochs=epochs,\n\u001b[0;32m---> 14\u001b[0;31m               num_threads=4, verbose=True)\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     patks = lightfm.evaluation.precision_at_k(model, test,\n",
      "\u001b[0;32m/home/whikwon/anaconda3/lib/python3.6/site-packages/lightfm/lightfm.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, interactions, user_features, item_features, sample_weight, epochs, num_threads, verbose)\u001b[0m\n\u001b[1;32m    409\u001b[0m                                 \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m                                 \u001b[0mnum_threads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_threads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m                                 verbose=verbose)\n\u001b[0m\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     def fit_partial(self, interactions,\n",
      "\u001b[0;32m/home/whikwon/anaconda3/lib/python3.6/site-packages/lightfm/lightfm.py\u001b[0m in \u001b[0;36mfit_partial\u001b[0;34m(self, interactions, user_features, item_features, sample_weight, epochs, num_threads, verbose)\u001b[0m\n\u001b[1;32m    503\u001b[0m                             \u001b[0msample_weight_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m                             \u001b[0mnum_threads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m                             self.loss)\n\u001b[0m\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/whikwon/anaconda3/lib/python3.6/site-packages/lightfm/lightfm.py\u001b[0m in \u001b[0;36m_run_epoch\u001b[0;34m(self, item_features, user_features, interactions, sample_weight, num_threads, loss)\u001b[0m\n\u001b[1;32m    542\u001b[0m                      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_alpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m                      \u001b[0mnum_threads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 544\u001b[0;31m                      self.random_state)\n\u001b[0m\u001b[1;32m    545\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'bpr'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m             fit_bpr(CSRMatrix(item_features),\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "space = [(1, 260), # epochs\n",
    "         (10**-4, 1.0, 'log-uniform'), # learning_rate\n",
    "         (20, 200), # no_components\n",
    "         (10**-6, 10**-1, 'log-uniform'), # alpha\n",
    "        ]\n",
    "\n",
    "res_fm = forest_minimize(objective, space, n_calls=250,\n",
    "                     random_state=0,\n",
    "                     verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Maximimum p@k found: {:6.5f}'.format(-res_fm.fun))\n",
    "print('Optimal parameters:')\n",
    "params = ['epochs', 'learning_rate', 'no_components', 'alpha']\n",
    "for (p, x_) in zip(params, res_fm.x):\n",
    "    print('{}: {}'.format(p, x_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No too shabby! We started with a p@k of ~0.034 with base hyperparameters, and then increased it to 0.0478 by finding better ones. Let's see what happens if we add in our item features as side information to the matrix factorization model.\n",
    "\n",
    "## Learning to Rank + Side Information\n",
    "\n",
    "```LightFM``` makes certain subtle assumptions when you do or do not pass side information. When no ```user_features``` or ```item_features``` are explicitly included, then ```LightFM``` assumes that both feature matrices are in fact identity matrices of size (```num_users``` X ```num_users```) or (```num_items``` X ```num_items```) for user and item feature matrices, respectively. What this is effectively doing is one-hot-encoding each user and item ID as a single feature vector. In the case where you do pass an ```item_features``` matrix, then ```LightFM``` does not do any one-hot-encoding. Thus, each user and item ID does not get its own vector unless you explicitly define one. The easiest way to do this is to make your own identity matrix and stack it on the side of the ```item_features``` matrix that we already created. This way, each item is described by a single vector for its unique ID and then a set of vectors for each of its tags."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 내용 뭐지 item ID에 대한 내용을 Identity matrix에 엎었다. 25655(item 수) x (25655(item id 정보) + 20352(item feature 수) 로 구성된다. id 정보를 넘겨주기 위해서 eye를 엎어준 것이라고 생각하면 된다. 흠..내부 코드를 안 보고 하기가 어렵다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Need to hstack item_features\n",
    "eye = sp.eye(item_features.shape[0], item_features.shape[0]).tocsr()\n",
    "item_features_concat = sp.hstack((eye, item_features))\n",
    "item_features_concat = item_features_concat.tocsr().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<25655x46007 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 187165 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_features_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<25655x20352 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 161510 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to define a new objective function that incorporates the ```item_features```.\n",
    "\n",
    "새로운 목적 함수에 ```item_features```에 관한 항이 추가되었다. 추가되는 정보는 어떻게 어떤 로직으로 학습이 되는거지?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def objective_wsideinfo(params):\n",
    "    # unpack\n",
    "    epochs, learning_rate,\\\n",
    "    no_components, item_alpha,\\\n",
    "    scale = params\n",
    "    \n",
    "    user_alpha = item_alpha * scale\n",
    "    model = LightFM(loss='warp',\n",
    "                    random_state=2016,\n",
    "                    learning_rate=learning_rate,\n",
    "                    no_components=no_components,\n",
    "                    user_alpha=user_alpha,\n",
    "                    item_alpha=item_alpha)\n",
    "    model.fit(train, epochs=epochs,\n",
    "              item_features=item_features_concat,\n",
    "              num_threads=4, verbose=True)\n",
    "    \n",
    "    patks = lightfm.evaluation.precision_at_k(model, test,\n",
    "                                              item_features=item_features_concat,\n",
    "                                              train_interactions=None,\n",
    "                                              k=5, num_threads=3)\n",
    "    mapatk = np.mean(patks)\n",
    "    # Make negative because we want to _minimize_ objective\n",
    "    out = -mapatk\n",
    "    # Weird shit going on\n",
    "    if np.abs(out + 1) < 0.01 or out < -1.0:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that defined, let's now run a new hyperparameter search. I will add an extra scaling parameter which will control the scaling between the user and item item regularization (alpha) terms. Because of all of the extra item features, we may want to regularize things differently. We'll also input an ```x0``` term to ```forest_minimization``` which will allow us to start our hyperparameter search at the optimal parameters from the previous run without side information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "space = [(1, 260), # epochs\n",
    "         (10**-3, 1.0, 'log-uniform'), # learning_rate\n",
    "         (20, 200), # no_components\n",
    "         (10**-5, 10**-3, 'log-uniform'), # item_alpha\n",
    "         (0.001, 1., 'log-uniform') # user_scaling\n",
    "        ]\n",
    "x0 = res_fm.x.append(1.)\n",
    "# This typecast is required\n",
    "item_features = item_features.astype(np.float32)\n",
    "res_fm_itemfeat = forest_minimize(objective_wsideinfo, space, n_calls=50,\n",
    "                                  x0=x0,\n",
    "                                  random_state=0,\n",
    "                                  verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Maximimum p@k found: {:6.5f}'.format(-res_fm_itemfeat.fun))\n",
    "print('Optimal parameters:')\n",
    "params = ['epochs', 'learning_rate', 'no_components', 'item_alpha', 'scaling']\n",
    "for (p, x_) in zip(params, res_fm_itemfeat.x):\n",
    "    print('{}: {}'.format(p, x_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you might be thinking \"Ethan, we went through all that only to get *worse* p@k?!\", and, frankly, I share your frustration. I've actually seen this happen before - adding side information will sometimes reduce or at least not increase whatever metric you're looking for. In all fairness, I only ran the above optimization for 50 calls, as opposed to the original one with 250 calls. This was mainly due to the matrix factorization model running much slower due to scaling with the number of user and item features. \n",
    "\n",
    "Even so, there are other reasons that the results could be worse. Maybe user behavior is a much better signal than human-defined tags and categories. The tag information could be poor for some of the models. As well, one may need to scale the tags *differently* compared to the unique ID vectors using, say, separate regularization terms, in order to get better behavior. Maybe one should normalize the tag weights by the number of tags. Maybe tags should not be included unless they have been used on at least ```X``` models. Maybe tags should only be included on models with few user interactions because after that ponit the cold start problem is sufficiently null. Who knows?! These are experiments I'd love to run, but I'd be happy to hear from others' experience.\n",
    "\n",
    "## Fun with Feature Embeddings\n",
    "\n",
    "Regardless of all of this, there is still a benefit to incorporating the item features. Because they have vectors embedded in the same space as the users and items, we can play with different types of recommendations. We'll first retrain the model on the full dataset using the optimal parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs, learning_rate,\\\n",
    "no_components, item_alpha,\\\n",
    "scale = res_fm_itemfeat.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x7f519a9e8710>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_alpha = item_alpha * scale\n",
    "model = LightFM(loss='warp',\n",
    "                random_state=2016,\n",
    "                learning_rate=learning_rate,\n",
    "                no_components=no_components,\n",
    "                user_alpha=user_alpha,\n",
    "                item_alpha=item_alpha)\n",
    "model.fit(likes, epochs=epochs,\n",
    "          item_features=item_features,\n",
    "          num_threads=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Sorting\n",
    "\n",
    "Imagine you're on Sketchfab and click the tag [tiltbrush](https://sketchfab.com/tags/tiltbrush) which would presumably correspond to models created with Google's [Tilt Brush](https://www.tiltbrush.com/) VR appliction. How should Sketchfab return the results to you? They currently return results based on the popularity of the items which is presumably not connected to the \"tiltbrushiness\" of the models. With the factorized tags, we can now return a list of products that are *most similar* to the tiltbrush tag sorted by that similarity. To do this, we must find the tiltbrush vector and measure the cosine similarity to every product.\n",
    "\n",
    "Recall that we tacked our identity matrix onto the left-hand side of the item_features matrix. This means that our ```DictVectorizer```, which mapped our item features to column indices of our ```item_features``` matrix, will have indices that are off by the number of items."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dictvectorizer에 문자값도 저장이 되는데 vocabulary_로 불러와보자.\n",
    "\n",
    "item_features는 `item x tag`로 이루어진 matrix이다. 그리고 dict는 `'tag': item_id'`로 이루어진다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = dv.vocabulary_['tag_sci-fi'] + item_features.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LightFM(loss='warp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x7fd1c2e5e390>"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train, item_features=item_features_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46007, 10)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.item_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15274, 10)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.user_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to calculate the cosine similarity between the tiltbrush vector and all other item *representations* where each item's representation is the sum of its feature vectors. These feature vectors are stored as ```item_embeddings``` in the LightFM model. (*Note: there are technically bias terms in the LightFM model that we are simply ignoring for now*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "구한 item embedding의 결과를 통해서 유사도를 구하자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tag를 고른 뒤 item을 예측한다.\n",
    "\n",
    "1~2 과정이 필요한 이유는 identity로 앞 부분을 지정했기 때문에 item_embedding으로 구한 결과가 \n",
    "\n",
    "1. tag의 vector는 item_embedding의 identity를 제외한 부분을 가리킨다고 한다. \n",
    "2. item을 나타내는 matrix는 item_feature와 item_embedding의 dot product이다. \n",
    "3. tag와 item을 나타내는 matrix 사이의 cosine similarity를 구한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46007"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_features_concat.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46007"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.item_embeddings.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cosine_similarity(vec, mat):\n",
    "    sim = vec.dot(mat.T)\n",
    "    matnorm = np.linalg.norm(mat, axis=1)\n",
    "    vecnorm = np.linalg.norm(vec)\n",
    "    return np.squeeze(sim / matnorm / vecnorm)\n",
    "\n",
    "# tag의 vector\n",
    "tilt_vec = model.item_embeddings[[idx], :]\n",
    "item_representations = item_features_concat.dot(model.item_embeddings)\n",
    "sims = cosine_similarity(tilt_vec, item_representations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25655, 10)"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_representations.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we can repurpose some code from the last blog post to visualize the top 5 Sketchfab model thumbnails that are most similar to the tiltbrush vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "def get_thumbnails(row, idx_to_mid, N=10):\n",
    "    thumbs = []\n",
    "    mids = []\n",
    "    for x in np.argsort(-row)[:N]:\n",
    "        response = requests.get('https://sketchfab.com/i/models/{}'\\\n",
    "                                .format(idx_to_mid[x])).json()\n",
    "        thumb = [x['url'] for x in response['thumbnails']['images']\n",
    "                 if x['width'] == 200 and x['height']==200]\n",
    "        if not thumb:\n",
    "            print('no thumbnail')\n",
    "        else:\n",
    "            thumb = thumb[0]\n",
    "        thumbs.append(thumb)\n",
    "        mids.append(idx_to_mid[x])\n",
    "    return thumbs, mids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "def display_thumbs(thumbs, mids, N=5):\n",
    "    thumb_html = \"<a href='{}' target='_blank'>\\\n",
    "                  <img style='width: 160px; margin: 0px; \\\n",
    "                  float: left; border: 1px solid black;' \\\n",
    "                  src='{}' /></a>\"\n",
    "    images = ''\n",
    "    for url, mid in zip(thumbs[0:N], mids[0:N]):\n",
    "        link = 'http://sketchfab.com/models/{}'.format(mid)\n",
    "        images += thumb_html.format(link, url)\n",
    "    display(HTML(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='http://sketchfab.com/models/b3f2ad526b334c14b90fc8f0510ea1cf' target='_blank'>                  <img style='width: 160px; margin: 0px;                   float: left; border: 1px solid black;'                   src='https://media.sketchfab.com/urls/b3f2ad526b334c14b90fc8f0510ea1cf/dist/thumbnails/11eb3d7fddfc4827ad144edb9da3c6e2/200x200.jpeg' /></a><a href='http://sketchfab.com/models/3829407459a24a24afa314d87845b45c' target='_blank'>                  <img style='width: 160px; margin: 0px;                   float: left; border: 1px solid black;'                   src='https://media.sketchfab.com/urls/3829407459a24a24afa314d87845b45c/dist/thumbnails/0838d315a42842e8a69ecad371fae320/200x200.jpeg' /></a><a href='http://sketchfab.com/models/35f81881ca404ecf98f2a39220c2d506' target='_blank'>                  <img style='width: 160px; margin: 0px;                   float: left; border: 1px solid black;'                   src='https://media.sketchfab.com/urls/35f81881ca404ecf98f2a39220c2d506/dist/thumbnails/5da7842eaa0a4a9bb073751a8a4cf150/200x200.jpeg' /></a><a href='http://sketchfab.com/models/7dade2368ab34f29850b24c95b920702' target='_blank'>                  <img style='width: 160px; margin: 0px;                   float: left; border: 1px solid black;'                   src='https://media.sketchfab.com/urls/7dade2368ab34f29850b24c95b920702/dist/thumbnails/758cecae1d7746419909233fe5a09235/200x200.jpeg' /></a><a href='http://sketchfab.com/models/13002c7255c643618f7f40a475a670ad' target='_blank'>                  <img style='width: 160px; margin: 0px;                   float: left; border: 1px solid black;'                   src='https://media.sketchfab.com/urls/13002c7255c643618f7f40a475a670ad/dist/thumbnails/8906e8a38a934eaa83c011d62a308277/200x200.jpeg' /></a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_thumbs(*get_thumbnails(sims, idx_to_mid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty cool! Looks like each of these are made with Tiltbrush. Feel free to click the above images to check out each model on the Sketchfab website.\n",
    "\n",
    "What else can we do?\n",
    "\n",
    "### Tag Suggestions\n",
    "\n",
    "Let's say that Sketchfab would like to encourage people to use more tags. This is advantageous to the company because it get users to create structured data for them for free while engaging the user. Sketchfab could encourage this behavior by suggesting tags to go with an image. One way we could do this would be to take a model and suggest tags to go with it that are not currently there. This involves finding tag vectors that are most similar to the model and then filtering tags that are already present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='http://sketchfab.com/models/381cbf8a06f042b9b41932f1f7ada997' target='_blank'>                  <img style='width: 200px; margin: 0px;                   float: left; border: 1px solid black;'                   src='https://media.sketchfab.com/urls/381cbf8a06f042b9b41932f1f7ada997/dist/thumbnails/5b486753baca47e9ad175a279a61eb11/200x200.jpeg' /></a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tags:\n",
      "- category_architecture\n",
      "- category_characters\n",
      "- category_cultural heritage\n",
      "- category_products & technology\n",
      "- category_science, nature & education\n",
      "- tag_rock\n",
      "- tag_sculpture\n",
      "- tag_woman\n"
     ]
    }
   ],
   "source": [
    "idx = 900\n",
    "mid = idx_to_mid[idx]\n",
    "def display_single(mid):\n",
    "    \"\"\"Display thumbnail for a single model\"\"\"\n",
    "    response = requests.get('https://sketchfab.com/i/models/{}'\\\n",
    "                            .format(mid)).json()\n",
    "    thumb = [x['url'] for x in response['thumbnails']['images']\n",
    "             if x['width'] == 200 and x['height']==200][0]\n",
    "    thumb_html = \"<a href='{}' target='_blank'>\\\n",
    "                  <img style='width: 200px; margin: 0px; \\\n",
    "                  float: left; border: 1px solid black;' \\\n",
    "                  src='{}' /></a>\"\n",
    "    link = 'http://sketchfab.com/models/{}'.format(mid)\n",
    "    display(HTML(thumb_html.format(link, thumb)))\n",
    "\n",
    "display_single(mid)\n",
    "\n",
    "# Make mapper to map from from feature index to feature name\n",
    "idx_to_feat = {v: k for (k, v) in dv.vocabulary_.items()}\n",
    "print('Tags:')\n",
    "for i in item_features.getrow(idx).indices:\n",
    "    print('- {}'.format(idx_to_feat[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### item을 고른 뒤 tag을 예측하자.\n",
    "1. item을 나타내는 vector는 item_features_concat의 idx번째 값과 item_embedding의 dot product이다.\n",
    "2. item을 나타내는 vector와 item을 나타내는 matrix 사이의 cosine similarity를 구한다.\n",
    "\n",
    "\n",
    "- `item_representation`: item의 특징을 나타낸다. <br>\n",
    "- `model.item_embeddings`: item 뿐 아니라 tag의 특징도 나타낸다.\n",
    "\n",
    "그래서 tag/item만의 특징을 얻기 위해서는 dot을 해줘야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested Tags:\n",
      "- tag_independent\n",
      "- tag_dronedeploy\n",
      "- tag_prehistoire\n",
      "- tag_prehistorique\n",
      "- tag_logical\n",
      "- tag_mechanical-calculator\n",
      "- tag_salerno\n",
      "- tag_operation\n",
      "- tag_rigs\n",
      "- tag_track-air\n"
     ]
    }
   ],
   "source": [
    "# Indices of all tag vectors\n",
    "tag_indices = set(v for (k, v) in dv.vocabulary_.items()\n",
    "                  if k.startswith('tag_'))\n",
    "# Tags that are already present\n",
    "filter_tags = set(i for i in item_features.getrow(idx).indices)\n",
    "\n",
    "item_representation = item_features_concat[idx, :].dot(model.item_embeddings)\n",
    "sims = cosine_similarity(item_representation, model.item_embeddings)\n",
    "\n",
    "suggested_tags = []\n",
    "i = 0\n",
    "recs = np.argsort(-sims)\n",
    "n_items = item_features.shape[0]\n",
    "\n",
    "# 아래에서 offset_idx는 item이 아닌 추천하는 tag를 나타낸다. \n",
    "while len(suggested_tags) < 10:\n",
    "    offset_idx = recs[i] - n_items\n",
    "    if offset_idx in tag_indices\\\n",
    "       and offset_idx not in filter_tags:\n",
    "        suggested_tags.append(idx_to_feat[offset_idx])\n",
    "    i += 1\n",
    "print('Suggested Tags:')\n",
    "for t in suggested_tags:\n",
    "    print('- {}'.format(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "item_representation = item_features_concat[idx, :].dot(model.item_embeddings)\n",
    "sims = cosine_similarity(item_representation, model.item_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Indices of all tag vectors\n",
    "tag_indices = set(v for (k, v) in dv.vocabulary_.items()\n",
    "                  if k.startswith('tag_'))\n",
    "# Tags that are already present\n",
    "filter_tags = set(i for i in item_features.getrow(idx).indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "suggested_tags = []\n",
    "i = 0\n",
    "recs = np.argsort(-sims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. recs가 추천 item이므로 이 순서대로 살펴봐야 한다. \n",
    "2. tag_indices에 있는지 확인한다. 안 속하면 tag가 없는 item\n",
    "3. tag를 가져온다.\n",
    "4. filter tag에 없으면 추가한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_items = item_features.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested Tags:\n",
      "- tag_actor\n",
      "- tag_head\n",
      "- tag_jason-statham\n",
      "- tag_lowpoly-gameasset-gameready\n",
      "- tag_realistic\n",
      "- tag_study\n",
      "- tag_base\n",
      "- tag_sci-fi\n",
      "- tag_science-fiction\n",
      "- tag_sciencefiction\n",
      "- tag_space\n",
      "- tag_spacegame\n",
      "- tag_spacestation\n"
     ]
    }
   ],
   "source": [
    "while len(suggested_tags) < 10:\n",
    "    offset_idx = recs[i] - n_items\n",
    "    tags_indices = item_features.getrow(offset_idx).indices\n",
    "    for tag_idx in tags_indices:\n",
    "        if tag_idx not in filter_tags:\n",
    "            tag = idx_to_feat[tag_idx]\n",
    "            if tag.startswith('tag_'):\n",
    "                suggested_tags.append(tag)\n",
    "    i += 1\n",
    "print('Suggested Tags:')\n",
    "for t in suggested_tags:\n",
    "    print('- {}'.format(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick conclusion\n",
    "\n",
    "So this post was long. There was a lot to learn and a lot of parameters to optimize. I'd like to note that, in terms of out of the box performance, it's hard to beat the ALS model from last post. There's fewer parameters to optimize, and the model is much more \"forgiving\" of being a bit off in your hyperparameters. Contrastingly, if your learning rate is poor, then SGD will give you *nothing* in return. It is definitely possible to beat ALS in performance, though, if you spend enough time fiddling around. Moreover, the ability to incorporate side information is important for being able to make new types of recommendations and overcome the cold start problem, so it's good to have this in your toolbox."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
