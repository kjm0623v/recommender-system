{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from lightfm.datasets import fetch_stackexchange\n",
    "\n",
    "data = fetch_stackexchange('crossvalidated',\n",
    "                           test_set_fraction=0.1,\n",
    "                           indicator_features=False,\n",
    "                           tag_features=True)\n",
    "\n",
    "train = data['train']\n",
    "test = data['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 3221 users and 72360 items, with 4307 interactions in the test and 57830 interactions in the training set.\n"
     ]
    }
   ],
   "source": [
    "print('The dataset has %s users and %s items, '\n",
    "      'with %s interactions in the test and %s interactions in the training set.'\n",
    "      % (train.shape[0], train.shape[1], test.getnnz(), train.getnnz()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 512 ms, sys: 0 ns, total: 512 ms\n",
      "Wall time: 283 ms\n"
     ]
    }
   ],
   "source": [
    "# Import the model\n",
    "from lightfm import LightFM\n",
    "\n",
    "# Set the number of threads; you can increase this\n",
    "# ify you have more physical cores available.\n",
    "NUM_THREADS = 2\n",
    "NUM_COMPONENTS = 30\n",
    "NUM_EPOCHS = 3\n",
    "ITEM_ALPHA = 1e-6\n",
    "\n",
    "# Let's fit a WARP model: these generally have the best performance.\n",
    "model = LightFM(loss='warp',\n",
    "                item_alpha=ITEM_ALPHA,\n",
    "               no_components=NUM_COMPONENTS)\n",
    "\n",
    "# Run 3 epochs and time it.\n",
    "%time model = model.fit(train, epochs=NUM_EPOCHS, num_threads=NUM_THREADS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collaborative filtering train AUC: 0.89248\n"
     ]
    }
   ],
   "source": [
    "# Import the evaluation routines\n",
    "from lightfm.evaluation import auc_score\n",
    "\n",
    "# Compute and print the AUC score\n",
    "train_auc = auc_score(model, train, num_threads=NUM_THREADS).mean()\n",
    "print('Collaborative filtering train AUC: %s' % train_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collaborative filtering test AUC: 0.352396\n"
     ]
    }
   ],
   "source": [
    "# We pass in the train interactions to exclude them from predictions.\n",
    "# This is to simulate a recommender system where we do not\n",
    "# re-recommend things the user has already interacted with in the train\n",
    "# set.\n",
    "test_auc = auc_score(model, test, train_interactions=train, num_threads=NUM_THREADS).mean()\n",
    "print('Collaborative filtering test AUC: %s' % test_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collaborative filtering test AUC: 0.498849\n"
     ]
    }
   ],
   "source": [
    "# Set biases to zero\n",
    "model.item_biases *= 0.0\n",
    "\n",
    "test_auc = auc_score(model, test, train_interactions=train, num_threads=NUM_THREADS).mean()\n",
    "print('Collaborative filtering test AUC: %s' % test_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1246 distinct tags, with values like ['bayesian', 'prior', 'elicitation'].\n"
     ]
    }
   ],
   "source": [
    "item_features = data['item_features']\n",
    "tag_labels = data['item_feature_labels']\n",
    "\n",
    "print('There are %s distinct tags, with values like %s.' % (item_features.shape[1], tag_labels[:3].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3221x72360 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 57830 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<72360x1246 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 198963 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a new model instance\n",
    "model = LightFM(loss='warp',\n",
    "                item_alpha=ITEM_ALPHA,\n",
    "                no_components=NUM_COMPONENTS)\n",
    "\n",
    "# Fit the hybrid model. Note that this time, we pass\n",
    "# in the item features matrix.\n",
    "model = model.fit(train,\n",
    "                item_features=item_features,\n",
    "                epochs=NUM_EPOCHS,\n",
    "                  \n",
    "                num_threads=NUM_THREADS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid training set AUC: 0.85693\n"
     ]
    }
   ],
   "source": [
    "# Don't forget the pass in the item features again!\n",
    "train_auc = auc_score(model,\n",
    "                      train,\n",
    "                      item_features=item_features,\n",
    "                      num_threads=NUM_THREADS).mean()\n",
    "print('Hybrid training set AUC: %s' % train_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid test set AUC: 0.701474\n"
     ]
    }
   ],
   "source": [
    "test_auc = auc_score(model,\n",
    "                    test,\n",
    "                    train_interactions=train,\n",
    "                    item_features=item_features,\n",
    "                    num_threads=NUM_THREADS).mean()\n",
    "print('Hybrid test set AUC: %s' % test_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar tags for bayesian: ['posterior' 'mcmc' 'prior']\n",
      "Most similar tags for regression: ['multiple-regression' 'regression-coefficients'\n",
      " 'generalized-least-squares']\n",
      "Most similar tags for survival: ['cox-model' 'kaplan-meier' 'adjustment']\n"
     ]
    }
   ],
   "source": [
    "def get_similar_tags(model, tag_id):\n",
    "    # Define similarity as the cosine of the angle\n",
    "    # between the tag latent vectors\n",
    "\n",
    "    # Normalize the vectors to unit length\n",
    "    tag_embeddings = (model.item_embeddings.T\n",
    "                      / np.linalg.norm(model.item_embeddings, axis=1)).T\n",
    "\n",
    "    query_embedding = tag_embeddings[tag_id]\n",
    "    similarity = np.dot(tag_embeddings, query_embedding)\n",
    "    most_similar = np.argsort(-similarity)[1:4]\n",
    "\n",
    "    return most_similar\n",
    "\n",
    "\n",
    "for tag in (u'bayesian', u'regression', u'survival'):\n",
    "    tag_id = tag_labels.tolist().index(tag)\n",
    "    print('Most similar tags for %s: %s' % (tag_labels[tag_id],\n",
    "                                            tag_labels[get_similar_tags(model, tag_id)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
